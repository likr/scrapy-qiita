name: CI

on:
  schedule:
    - cron:  '0 0 * * 0'

jobs:
  build:

    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v1
    - uses: actions/setup-python@v1
      with:
        python-version: 3.7
    - uses: GoogleCloudPlatform/github-actions/setup-gcloud@master
      with:
          version: '270.0.0'
          service_account_email: ${{ secrets.GCP_SA_EMAIL }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
    - name: crawl
      run: |
        pip install -r requirements.txt
        scrapy crawl items -o items`date "+%Y%m%d"`.json -t jsonlines --nolog
        gsutil cp qiita`date "+%Y%m%d"`.json gs://vdslab/qiita/
        bq --project=vdslab-207906 --dataset_id=qiita mk --table --force --expiration=2419200  items`date "+%Y%m%d"`
        bq --project=vdslab-207906 load --source_format=NEWLINE_DELIMITED_JSON qiita.items`date "+%Y%m%d"` gs://vdslab/qiita/items`date "+%Y%m%d"`.json scheme.json
      env:
        QIITA_TOKEN:  ${{ secrets.QIITA_TOKEN }}
